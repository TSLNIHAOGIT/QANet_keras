{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qanet_fit_demp\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.initializers import *\n",
    "# from QANet_keras import QANet\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#关闭eager模式\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# tf.keras.backend.set_learning_phase(1)  # training\n",
    "\n",
    "#就代表生成10000行 300列的浮点数，浮点数都是从0-1中随机。\n",
    "##模拟的是预训练的词向量，生成QAnet模型，然后训练时对于某个词，该词存在该向量中，就取出该词向量进行使用，不存在就使用随机的词向量\n",
    "##所以模型中一定有embedding模块\n",
    "\n",
    "##假设总共10000个单词，每个单词300维度 \n",
    "embedding_matrix = np.random.random((10000, 300))\n",
    "##总共1233个字符，每个字符64维度\n",
    "embedding_matrix_char = np.random.random((1233, 64))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    'word_dim': 300,\n",
    "    'char_dim': 64,\n",
    "    'cont_limit': 400,\n",
    "    'ques_limit': 50,\n",
    "    'char_limit': 16,\n",
    "    'ans_limit': 30,\n",
    "    'char_input_size': 1233,\n",
    "    'filters': 128,\n",
    "    'num_head': 8,\n",
    "    'dropout': 0.5,\n",
    "    'batch_size': 16,\n",
    "    'epoch': 25,\n",
    "    'ema_decay': 0.9999,\n",
    "    'learning_rate': 1e-3,\n",
    "    'path': 'QA001',\n",
    "    'use_cove': True\n",
    "}\n",
    "\n",
    "\n",
    "# load data\n",
    "char_dim = 200##好像没有使用\n",
    "cont_limit = 400\n",
    "ques_limit = 50\n",
    "char_limit = 16\n",
    "\n",
    "###0-10000之间的某个词模拟所有词的的index\n",
    "##embedding词典大小总共10000个单词；转成0-9999个索引对应，300个上下文，每个上下文长度最大为为400\n",
    "context_word = np.random.randint(0, 10000, (300, cont_limit))\n",
    "question_word = np.random.randint(0, 10000, (300, ques_limit))\n",
    "context_char = np.random.randint(0, 96, (300, cont_limit, char_limit))\n",
    "question_char = np.random.randint(0, 96, (300, ques_limit, char_limit))\n",
    "\n",
    "##300个答案与300个问题一一对应\n",
    "start_label = np.random.randint(0, 2, (300, cont_limit))\n",
    "end_label = np.random.randint(0, 2, (300, cont_limit))\n",
    "start_label_fin = np.argmax(start_label, axis=-1)\n",
    "end_label_fin = np.argmax(end_label, axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qanet_keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "# tf.keras.initializers.VarianceScaling\n",
    "# from layers.context2query_attention import context2query_attention\n",
    "\n",
    "# from layers.multihead_attention import Attention as MultiHeadAttention\n",
    "# from layers.position_embedding import Position_Embedding as PositionEmbedding\n",
    "# from layers.layer_norm import LayerNormalization\n",
    "# from layers.layer_dropout import LayerDropout\n",
    "# from layers.QAoutputBlock import QAoutputBlock\n",
    "# from layers.BatchSlice import BatchSlice\n",
    "# from layers.DepthwiseConv1D import DepthwiseConv1D\n",
    "# from layers.LabelPadding import LabelPadding\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "# parameters\n",
    "word_dim = config['word_dim']\n",
    "char_dim = config['char_dim']\n",
    "cont_limit = config['cont_limit']\n",
    "char_limit = config['char_limit']\n",
    "ans_limit = config['ans_limit']\n",
    "filters = config['filters']\n",
    "num_head = config['num_head']\n",
    "dropout = config['dropout']\n",
    "\n",
    "# Input Embedding Layer\n",
    "#`Input()` is used to instantiate a Keras tensor.S\n",
    "'''\n",
    "for example:\n",
    "inp = Input(shape=(maxlen,))\n",
    "计算得到\n",
    "inp.shape=(None, maxlen)\n",
    "shape: A shape tuple (integer), not including the batch size. For instance, \n",
    "shape=(32,)indicates that the expected input will be batches of 32-dimensional vectors.\n",
    "也就是说，不看batch_size的话，其实我们输入的是一个100维度的向量，正好对应了上面的maxlen对吧。\n",
    "\n",
    "那我们embedding层的作用，是将正整数下标转换为具有固定大小的向量。\n",
    "\n",
    "如[[4], [20]]->[[0.25,0.1], [0.6,-0.2]]。一定要注意到一个下标对应一个向量。\n",
    "\n",
    "'''\n",
    "#相当于词向量的维度是输入的None,完整的维度是(None,None)=（glove词向量中总的单词数，每个单词的维度）\n",
    "#第一个None是默认的词的个数（batch_size），第二None是自己输入的词向量的维度\n",
    "####这个不是用于词向量的，是为了获得mask矩阵\n",
    "\n",
    "\n",
    "contw_input_ = Input((None,))## [bs, c_len]=[上下文总数,每个上下文单词数]\n",
    "quesw_input_ = Input((None,))\n",
    "\n",
    "#（None,char_limit）可能代表（单词个数，每个单词的字符数），总体应该是（上下文总数，每个上下文单词数，每个单词字符数）\n",
    "contc_input_ = Input((None, char_limit))\n",
    "quesc_input_ = Input((None, char_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('input test',Input((111,222)))\n",
    "# print('contw_input_ :',contw_input_ )\n",
    "# print('contc_input_:',contc_input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###直接替换input层:调试看维度是可以这样使用，构建模型时还是要使用input层\n",
    "# ###模拟是最长的大小，没有进行0补的0\n",
    "# '''\n",
    "# cont_limit = 400\n",
    "# ques_limit = 50\n",
    "# char_limit = 16\n",
    "# '''\n",
    "\n",
    "# contw_input_= np.random.randint(0, 10000, (300, cont_limit))\n",
    "# quesw_input_ = np.random.randint(0, 10000, (300, ques_limit))\n",
    "# contc_input_  = np.random.randint(0, 96, (300, cont_limit, char_limit))\n",
    "# quesc_input_ = np.random.randint(0, 96, (300, ques_limit, char_limit))\n",
    "\n",
    "# print('contw_input_ :',contw_input_.shape )\n",
    "# print('contc_input_:',contc_input_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mask\n",
    "#里面都是词典对应的id,且短的已经用零补全了，因此能转为布尔值计算mask矩阵\n",
    "c_mask = Lambda(lambda x: tf.cast(x, tf.bool))(contw_input_)  # [bs, c_len]\n",
    "q_mask = Lambda(lambda x: tf.cast(x, tf.bool))(quesw_input_)\n",
    "#reduce_sum默认是对所有元素求和\n",
    "\n",
    "##axis=1是对行求和,就是求每个context的长度\n",
    "cont_len = Lambda(lambda x: tf.expand_dims(tf.reduce_sum(tf.cast(x, tf.int32), axis=1), axis=1))(c_mask)\n",
    "ques_len = Lambda(lambda x: tf.expand_dims(tf.reduce_sum(tf.cast(x, tf.int32), axis=1), axis=1))(q_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_mask (None, None)\n",
      "ques_len (None, 1)\n",
      "cont_len (None, 1)\n"
     ]
    }
   ],
   "source": [
    "# c_mask0=[[1,1,1,1,0],[1,1,1,0,0]]\n",
    "\n",
    "# print('tf.reduce_sum(tf.cast(x, tf.int32):',tf.reduce_sum(tf.cast(c_mask0, tf.int32),axis=1))\n",
    "# print('expand_dims',tf.expand_dims(tf.reduce_sum(tf.cast(c_mask0, tf.int32),axis=1),axis=1))\n",
    "print('c_mask',c_mask.shape)\n",
    "print('ques_len',ques_len.shape)\n",
    "print('cont_len',cont_len.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer \n",
    "import tensorflow as tf\n",
    "\n",
    "class BatchSlice(Layer):\n",
    "    def __init__(self, dim=2, **kwargs):\n",
    "        self.dim = dim\n",
    "        super(BatchSlice, self).__init__(**kwargs)\n",
    "    '''\n",
    "    build(input_shape): 这是你定义权重的地方。这个方法必须设 self.built = True，可以通过调用 super([Layer], self).build() 完成\n",
    "    '''\n",
    "    def build(self, input_shape):\n",
    "        super(BatchSlice, self).build(input_shape)\n",
    "    '''\n",
    "    call(x): 这里是编写层的功能逻辑的地方。你只需要关注传入 call 的第一个参数：输入张量，除非你希望你的层支持masking。\n",
    "    '''\n",
    "    #eg input=[contw_input_, cont_len]\n",
    "    def call(self, x, mask=None):\n",
    "        \n",
    "        x, length = x # [bs, len, dim]\n",
    "        ##选取上下文长度中最长的一个，作为最终的长度\n",
    "        length = tf.cast(tf.reduce_max(length), tf.int32)\n",
    "        st = [0] * self.dim\n",
    "        ed = [-1] * self.dim\n",
    "        ed[1] = length\n",
    "        \n",
    "        #从开始位置x[st]抽取元素，各个维度对应的元素个数为ed\n",
    "        #此处 x=[batch_size,each_context_length]\n",
    "         #    st=[0,0]\n",
    "        #   ed=[-1,max_len_context]\n",
    "        \n",
    "        #即从第0个元素开始，抽取每个上下文都\n",
    "        x = tf.slice(x, st, ed)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qanet_keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "# tf.keras.initializers.VarianceScaling\n",
    "# from layers.context2query_attention import context2query_attention\n",
    "\n",
    "# from layers.multihead_attention import Attention as MultiHeadAttention\n",
    "# from layers.position_embedding import Position_Embedding as PositionEmbedding\n",
    "# from layers.layer_norm import LayerNormalization\n",
    "# from layers.layer_dropout import LayerDropout\n",
    "# from layers.QAoutputBlock import QAoutputBlock\n",
    "# from layers.BatchSlice import BatchSlice\n",
    "# from layers.DepthwiseConv1D import DepthwiseConv1D\n",
    "# from layers.LabelPadding import LabelPadding\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice\n",
    "##contw_input_:（上下文个数，每个上下文词个数） cont_len：（所有上下文长度，1）\n",
    "##暂时还不知道切片的目的是什么，理论上应该是输入的文本长度太长时，要截取一部分，太短时要补全一部分\n",
    "##但是输入时已经是一个矩阵了，意思是已经进行了截取或者补全之后的矩阵了，再次截取时只会再截取一部分数据过来，丢掉一部分数据\n",
    "\n",
    "\n",
    "##dim=2或者3都是从头开始截取，对context的长度进行截断（没有对word长度截断）\n",
    "contw_input = BatchSlice(dim=2)([contw_input_, cont_len])\n",
    "quesw_input = BatchSlice(dim=2)([quesw_input_, ques_len])\n",
    "contc_input = BatchSlice(dim=3)([contc_input_, cont_len])\n",
    "quesc_input = BatchSlice(dim=3)([quesc_input_, ques_len])\n",
    "\n",
    "##对mask进行截取构成新的mask矩阵\n",
    "c_mask = BatchSlice(dim=2)([c_mask, cont_len])\n",
    "q_mask = BatchSlice(dim=2)([q_mask, ques_len])\n",
    "\n",
    "##上下文和问题的最大长度\n",
    "c_maxlen = tf.cast(tf.reduce_max(cont_len), tf.int32)\n",
    "q_maxlen = tf.cast(tf.reduce_max(ques_len), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[contw_input_, cont_len] [<tf.Tensor 'input_1:0' shape=(None, None) dtype=float32>, <tf.Tensor 'lambda_2/ExpandDims:0' shape=(None, 1) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "print('[contw_input_, cont_len]',[contw_input_, cont_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1106 04:54:03.201857 139837375031040 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    " # embedding word\n",
    "word_mat=embedding_matrix\n",
    "char_mat=embedding_matrix_char\n",
    "\n",
    "#第一个参数词汇表大小，第二个参数是词向量维度，weights是embedding层权重初始化的一种方式：此处就是用word_mat来初始化embedding层\n",
    "WordEmbedding = Embedding(word_mat.shape[0], word_dim, weights=[word_mat], trainable=False, name='word_embedding')\n",
    "#根据词汇表索引去取相应的embedding值\n",
    "xw_cont = WordEmbedding(contw_input)\n",
    "xw_ques = WordEmbedding(quesw_input)\n",
    "\n",
    "\n",
    "####词向量初始化之后的值；可以用bert初始化的词向量进行替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordEmbedding <tensorflow.python.keras.layers.embeddings.Embedding object at 0x7f2dff22d7b8>\n",
      "xw_cont (None, None, 300)\n",
      "xw_ques (None, None, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nxw_cont (300, 400, 300)=(batch_size,content_length,word_embedding_size)\\nxw_ques (300, 50, 300)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('WordEmbedding',WordEmbedding)\n",
    "print('xw_cont',xw_cont.shape)\n",
    "print('xw_ques',xw_ques.shape)\n",
    "'''\n",
    "xw_cont (300, 400, 300)=(batch_size,content_length,word_embedding_size)\n",
    "xw_ques (300, 50, 300)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cove_model=None\n",
    "# cove##暂时没有看这个源代码\n",
    "if cove_model is not None:\n",
    "    x_cont_cove = cove_model(xw_cont)\n",
    "    x_ques_cove = cove_model(xw_ques)\n",
    "    xw_cont = Concatenate()([xw_cont, x_cont_cove])\n",
    "    xw_ques = Concatenate()([xw_ques, x_ques_cove])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding char\n",
    "CharEmbedding = Embedding(char_mat.shape[0], char_dim, weights=[char_mat], name='char_embedding')\n",
    "xc_cont = CharEmbedding(contc_input)\n",
    "xc_ques = CharEmbedding(quesc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xc_cont (None, None, None, 64)\n",
      "xc_ques (None, None, None, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nxc_cont (300, 400, 16, 64)=(batch_size,content_length,word_length,char_embedding_size)\\nxc_ques (300, 50, 16, 64)\\n##字符embedding是随机初始化后进行训练的\\n\\n经过reshape, Conv1D(filters, 5）变为：\\n#xc_context将前两个维度合并为300*400=120000个词汇（含重复的）\\n#(300*400,16,64)然后送入conv1d卷积层:输出为（batch_size=120000,new_step=16-5+1,filters=128）\\n\\n经过对第二个维度如time_step进行最大池化，那么对所有step第一个元素取最大值，第二个元素取最大值等等\\n##与bert分类时池化类似，那里是去第一个，这是最大的一个  \\n##xc_cont = GlobalMaxPooling1D()(xc_cont)；变为xc_cont (120000, 128) xc_ques (15000, 128)\\n\\n经过reshape之后变为：xc_cont (300, 400, 128)\\n\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('xc_cont',xc_cont.shape)\n",
    "print('xc_ques',xc_ques.shape)\n",
    "'''\n",
    "xc_cont (300, 400, 16, 64)=(batch_size,content_length,word_length,char_embedding_size)\n",
    "xc_ques (300, 50, 16, 64)\n",
    "##字符embedding是随机初始化后进行训练的\n",
    "\n",
    "经过reshape, Conv1D(filters, 5）变为：\n",
    "#xc_context将前两个维度合并为300*400=120000个词汇（含重复的）\n",
    "#(300*400,16,64)然后送入conv1d卷积层:输出为（batch_size=120000,new_step=16-5+1,filters=128）\n",
    "\n",
    "经过对第二个维度如time_step进行最大池化，那么对所有step第一个元素取最大值，第二个元素取最大值等等\n",
    "##与bert分类时池化类似，那里是去第一个，这是最大的一个  \n",
    "##xc_cont = GlobalMaxPooling1D()(xc_cont)；变为xc_cont (120000, 128) xc_ques (15000, 128)\n",
    "\n",
    "经过reshape之后变为：xc_cont (300, 400, 128)\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = l2(3e-7)\n",
    "init = VarianceScaling(scale=1.0, mode='fan_avg', distribution='uniform')\n",
    "init_relu = VarianceScaling(scale=2.0, mode='fan_in', distribution='normal')\n",
    "\n",
    "char_conv = Conv1D(filters, 5,\n",
    "                   activation='relu',\n",
    "                   kernel_initializer=init_relu,\n",
    "                   kernel_regularizer=regularizer,\n",
    "                   name='char_conv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xc_context将前两个维度合并为300*400=120000个词汇（含重复的）\n",
    "#(300*400,16,64)然后送入conv1d卷积层:输出为（batch_size=120000,new_step=16-5+1,filters=128）\n",
    "#一维卷积中kernl_size=5卷积核大小为5，但是移动幅度默认为1,16-5=11，\n",
    "#下面移动11词，加上第一次的总共12次；#filters卷积核个数，最终将每个卷积核的结果拼接到一起；\n",
    "xc_cont = Lambda(lambda x: tf.reshape(x, (-1, char_limit, char_dim)))(xc_cont)\n",
    "xc_ques = Lambda(lambda x: tf.reshape(x, (-1, char_limit, char_dim)))(xc_ques)\n",
    "xc_cont = char_conv(xc_cont)\n",
    "xc_ques = char_conv(xc_ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xc_cont (None, 12, 128)\n",
      "xc_ques (None, 12, 128)\n"
     ]
    }
   ],
   "source": [
    "print('xc_cont',xc_cont.shape)\n",
    "print('xc_ques',xc_ques.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##对第二个维度如time_step进行最大池化，那么对所有step第一个元素取最大值，第二个元素取最大值等等\n",
    "xc_cont = GlobalMaxPooling1D()(xc_cont)\n",
    "xc_ques = GlobalMaxPooling1D()(xc_ques)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"global_max_pooling1d_2/Max:0\", shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x_t=[\n",
    "    [[11,0,3],[0,12,8],[9,7,13]],\n",
    "    [[111,0,3],[0,122,8],[9,7,133]],\n",
    "]\n",
    "x_t=tf.constant(x_t)\n",
    "print(GlobalMaxPooling1D()(x_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xc_cont (None, 128)\n",
      "xc_ques (None, 128)\n"
     ]
    }
   ],
   "source": [
    "print('xc_cont',xc_cont.shape)\n",
    "print('xc_ques',xc_ques.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape\n",
    "xc_cont = Lambda(lambda x: tf.reshape(x, (-1, c_maxlen, filters)))(xc_cont)\n",
    "xc_ques = Lambda(lambda x: tf.reshape(x, (-1, q_maxlen, filters)))(xc_ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xc_cont (None, None, 128)\n",
      "xc_ques (None, None, 128)\n"
     ]
    }
   ],
   "source": [
    "print('xc_cont',xc_cont.shape)\n",
    "print('xc_ques',xc_ques.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# highwayNet\n",
    "# (300,400,300) (300,400,128)\n",
    "##concatenate 默认axis=-1，即沿着最后一轴进行拼接\n",
    "x_cont = Concatenate()([xw_cont, xc_cont])\n",
    "x_ques = Concatenate()([xw_ques, xc_ques])\n",
    "\n",
    "\n",
    "##这里上下和问题的词嵌入都做好了，可以放到下面求attention进行使用了\n",
    "##最终bert做好的词向量可以在这里进行替换（batch_size,seq_length,hidden_size）\n",
    "##对应到图片上：一页就是一句话，一个识别内容就是一个单词，一个识别内容的向量就是相应的词向量\n",
    "##将context即一句话复制成与问题同样多的条数；即可构建相应的数据矩阵\n",
    "##一页中对于后面的位置embedding,不需要做，直接替换为相应的坐标即可。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_cont (None, None, 428)\n",
      "x_ques (None, None, 428)\n"
     ]
    }
   ],
   "source": [
    "print('x_cont',x_cont.shape)\n",
    "print('x_ques',x_ques.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highway(highway_layers, x, num_layers=2, dropout=0.1):\n",
    "    # reduce dim\n",
    "    x = highway_layers[0](x)\n",
    "    for i in range(num_layers):\n",
    "        T = highway_layers[i * 2 + 1](x)\n",
    "        H = highway_layers[i * 2 + 2](x)\n",
    "        H = Dropout(dropout)(H)\n",
    "        # H*T+x*(1-T)\n",
    "        x = Lambda(lambda v: v[0] * v[1] + v[2] * (1 - v[1]))([H, T, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters=128\n",
    "# highway shared layers\n",
    "highway_layers = [Conv1D(filters, 1,\n",
    "                         kernel_initializer=init,\n",
    "                         kernel_regularizer=regularizer,\n",
    "                         name='highway_input_projection')]\n",
    "for i in range(2):\n",
    "    highway_layers.append(Conv1D(filters, 1,\n",
    "                                 kernel_initializer=init,\n",
    "                                 kernel_regularizer=regularizer,\n",
    "                                 activation='sigmoid',\n",
    "                                 name='highway' + str(i) + '_gate'))\n",
    "    highway_layers.append(Conv1D(filters, 1,\n",
    "                                 kernel_initializer=init,\n",
    "                                 kernel_regularizer=regularizer,\n",
    "                                 activation='linear',\n",
    "                                 name='highway' + str(i) + '_linear'))\n",
    "x_cont = highway(highway_layers, x_cont, num_layers=2, dropout=dropout)\n",
    "x_ques = highway(highway_layers, x_ques, num_layers=2, dropout=dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_cont (None, None, 128)\n",
      "x_ques (None, None, 128)\n"
     ]
    }
   ],
   "source": [
    "print('x_cont',x_cont.shape)\n",
    "print('x_ques',x_ques.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseConv1D(Layer):\n",
    "\n",
    "    def __init__(self, kernel_size, filter, **kwargs):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.filter = filter\n",
    "        super(DepthwiseConv1D, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        init_relu = VarianceScaling(scale=2.0, mode='fan_in', distribution='normal')\n",
    "        self.depthwise_w = self.add_weight(\"depthwise_filter\",\n",
    "                                           shape=(self.kernel_size, 1, input_shape[-1], 1),\n",
    "                                           initializer=init_relu,\n",
    "                                           regularizer=l2(3e-7),\n",
    "                                           trainable=True)\n",
    "        self.pointwise_w = self.add_weight(\"pointwise_filter\",\n",
    "                                           (1, 1, input_shape[-1], self.filter),\n",
    "                                           initializer=init_relu,\n",
    "                                           regularizer=l2(3e-7),\n",
    "                                           trainable=True)\n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                    input_shape[-1],\n",
    "                                    regularizer=l2(3e-7),\n",
    "                                    initializer=tf.zeros_initializer())\n",
    "        super(DepthwiseConv1D, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        x = K.expand_dims(x, axis=2)\n",
    "        x = tf.nn.separable_conv2d(x,\n",
    "                                   self.depthwise_w,\n",
    "                                   self.pointwise_w,\n",
    "                                   strides=(1, 1, 1, 1),\n",
    "                                   padding=\"SAME\")\n",
    "        x += self.bias\n",
    "        x = K.relu(x)\n",
    "        outputs = K.squeeze(x, axis=2)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, units, num_heads, dropout=0.1, bias=True, **kwargs):\n",
    "        self.units = units\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.bias = bias\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(name='bias',\n",
    "                                     shape=([1]),\n",
    "                                     initializer='zero')\n",
    "        super(MultiHeadAttention, self).build(input_shape)\n",
    "\n",
    "    def split_last_dimension(self, x, n):\n",
    "        old_shape = x.get_shape().dims\n",
    "        last = old_shape[-1]\n",
    "        new_shape = old_shape[:-1] + [n] + [last // n if last else None]\n",
    "        ret = tf.reshape(x, tf.concat([tf.shape(x)[:-1], [n, -1]], 0))\n",
    "        ret.set_shape(new_shape)\n",
    "        return tf.transpose(ret, [0, 2, 1, 3])\n",
    "\n",
    "    def mask_logits(self, inputs, mask, mask_value=-1e30):\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "        return inputs + mask_value * (1 - mask)\n",
    "\n",
    "    def dot_product_attention(self, x, mask=None, dropout=0.1, training=None):\n",
    "        q, k, v = x\n",
    "        logits = tf.matmul(q, k, transpose_b=True)  # [bs, 8, len, len]\n",
    "        if self.bias:\n",
    "            logits += self.b\n",
    "        if mask is not None:  # [bs, len]\n",
    "            mask = tf.expand_dims(mask, axis=1)\n",
    "            mask = tf.expand_dims(mask, axis=1)  # [bs,1,1,len]\n",
    "            logits = self.mask_logits(logits, mask)\n",
    "        weights = tf.nn.softmax(logits, name=\"attention_weights\")\n",
    "        weights = K.in_train_phase(K.dropout(weights, dropout), weights, training=training)\n",
    "        x = tf.matmul(weights, v)\n",
    "        return x\n",
    "\n",
    "    def combine_last_two_dimensions(self, x):\n",
    "        old_shape = x.get_shape().dims\n",
    "        a, b = old_shape[-2:]\n",
    "        new_shape = old_shape[:-2] + [a * b if a and b else None]\n",
    "        ret = tf.reshape(x, tf.concat([tf.shape(x)[:-2], [-1]], 0))\n",
    "        ret.set_shape(new_shape)\n",
    "        return ret\n",
    "\n",
    "    def call(self, x, mask=None, training=None):\n",
    "        memory, query, seq_mask = x\n",
    "        Q = self.split_last_dimension(query, self.num_heads)\n",
    "        memory = tf.split(memory, 2, axis=2)\n",
    "        K = self.split_last_dimension(memory[0], self.num_heads)\n",
    "        V = self.split_last_dimension(memory[1], self.num_heads)\n",
    "\n",
    "        key_depth_per_head = self.units // self.num_heads\n",
    "        Q *= (key_depth_per_head ** -0.5)\n",
    "        x = self.dot_product_attention([Q, K, V], seq_mask, dropout=self.dropout, training=training)\n",
    "        x = self.combine_last_two_dimensions(tf.transpose(x, [0, 2, 1, 3]))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build shared layers\n",
    "# shared convs\n",
    "Encoder_DepthwiseConv1 = []\n",
    "for i in range(4):\n",
    "    Encoder_DepthwiseConv1.append(DepthwiseConv1D(7, filters))\n",
    "\n",
    "# shared attention\n",
    "Encoder_SelfAttention1 = [Conv1D(2 * filters, 1,\n",
    "                                 kernel_initializer=init,\n",
    "                                 kernel_regularizer=regularizer),\n",
    "                          Conv1D(filters, 1,\n",
    "                                 kernel_initializer=init,\n",
    "                                 kernel_regularizer=regularizer),\n",
    "                          MultiHeadAttention(filters, num_head, dropout=dropout, bias=False)]\n",
    "# shared feed-forward\n",
    "Encoder_FeedForward1 = []\n",
    "Encoder_FeedForward1.append(Conv1D(filters, 1,\n",
    "                                   kernel_initializer=init,\n",
    "                                   kernel_regularizer=regularizer,\n",
    "                                   activation='relu'))\n",
    "Encoder_FeedForward1.append(Conv1D(filters, 1,\n",
    "                                   kernel_initializer=init,\n",
    "                                   kernel_regularizer=regularizer,\n",
    "                                   activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class Position_Embedding(Layer):\n",
    "    def __init__(self, min_timescale=1.0, max_timescale=1.0e4, **kwargs):\n",
    "        self.min_timescale = min_timescale\n",
    "        self.max_timescale = max_timescale\n",
    "        super(Position_Embedding, self).__init__(**kwargs)\n",
    "\n",
    "    def get_timing_signal_1d(self, length, channels):\n",
    "        position=tf.cast(tf.range(length),dtype=tf.float32)\n",
    "        num_timescales = channels // 2\n",
    "        log_timescale_increment = (math.log(float(self.max_timescale) / float(self.min_timescale)) / (tf.cast(num_timescales,dtype=tf.float32) - 1))\n",
    "        inv_timescales = self.min_timescale * tf.exp(tf.cast(tf.range(num_timescales),dtype=tf.float32) * -log_timescale_increment)\n",
    "        scaled_time = tf.expand_dims(position, 1) * tf.expand_dims(inv_timescales, 0)\n",
    "        signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)\n",
    "        signal = tf.pad(signal, [[0, 0], [0, tf.math.mod(channels, 2)]])\n",
    "        signal = tf.reshape(signal, [1, length, channels])\n",
    "        return signal\n",
    "\n",
    "    def add_timing_signal_1d(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        channels = tf.shape(x)[2]\n",
    "        signal = self.get_timing_signal_1d(length, channels)\n",
    "        \n",
    "        ##这里是词向量和位置向量直接相加；那个地方可能是拼接或者在接一层后进行输入\n",
    "        return x + signal\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return self.add_timing_signal_1d(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "PositionEmbedding=Position_Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class LayerDropout(Layer):\n",
    "    def __init__(self, dropout = 0.1, **kwargs):\n",
    "        self.dropout = dropout\n",
    "        super(LayerDropout, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(LayerDropout, self).build(input_shape)\n",
    "    #0.2 should be self.dropout，但这里总是出错，就先改成0.2\n",
    "    def call(self, x, mask=None, training=None):\n",
    "        x, residual = x\n",
    "        pred = tf.random.uniform([]) < self.dropout\n",
    "        #print('self.dropout',self.dropout)\n",
    "        x_train = tf.cond(pred, lambda: residual, lambda: tf.nn.dropout(x, 1.0 -0.2 ) + residual)\n",
    "        x_test = x + residual\n",
    "        return K.in_train_phase(x_train, x_test, training=training)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(conv_layers, x, num_conv=4, dropout=0.1, l=1., L=1.):\n",
    "    for i in range(num_conv):\n",
    "        residual = x\n",
    "        x = LayerNormalization()(x)\n",
    "        if i % 2 == 0:\n",
    "            x = Dropout(dropout)(x)\n",
    "        x = conv_layers[i](x)\n",
    "        x = LayerDropout(dropout * (l / L))([x, residual])\n",
    "    return x\n",
    "def attention_block(attention_layer, x, seq_mask, dropout=0.1, l=1., L=1.):\n",
    "    residual = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x1 = attention_layer[0](x)\n",
    "    x2 = attention_layer[1](x)\n",
    "    x = attention_layer[2]([x1, x2, seq_mask])\n",
    "    x = LayerDropout(dropout * (l / L))([x, residual])\n",
    "    return x\n",
    "\n",
    "\n",
    "def feed_forward_block(FeedForward_layers, x, dropout=0.1, l=1., L=1.):\n",
    "    residual = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = FeedForward_layers[0](x)\n",
    "    x = FeedForward_layers[1](x)\n",
    "    x = LayerDropout(dropout * (l / L))([x, residual])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1106 04:54:04.694412 139837375031040 nn_ops.py:4283] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1106 04:54:04.795206 139837375031040 nn_ops.py:4283] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1106 04:54:04.930246 139837375031040 nn_ops.py:4283] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1106 04:54:05.029911 139837375031040 nn_ops.py:4283] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1106 04:54:06.050738 139837375031040 nn_ops.py:4283] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "# Context Embedding Encoder Layer\n",
    "x_cont = PositionEmbedding()(x_cont)\n",
    "x_cont = conv_block(Encoder_DepthwiseConv1, x_cont, 4, dropout)\n",
    "x_cont = attention_block(Encoder_SelfAttention1, x_cont, c_mask, dropout)\n",
    "x_cont = feed_forward_block(Encoder_FeedForward1, x_cont, dropout)\n",
    "\n",
    "# Question Embedding Encoder Layer\n",
    "x_ques = PositionEmbedding()(x_ques)\n",
    "x_ques = conv_block(Encoder_DepthwiseConv1, x_ques, 4, dropout)\n",
    "x_ques = attention_block(Encoder_SelfAttention1, x_ques, q_mask, dropout)\n",
    "x_ques = feed_forward_block(Encoder_FeedForward1, x_ques, dropout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_cont=(None, None, 128)\n",
      "  x_ques=(None, None, 128)\n",
      "  c_mask=(None, None)\n",
      "  q_mask=(None, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('x_cont={}\\n  x_ques={}\\n  c_mask={}\\n  q_mask={}\\n'.format(x_cont.shape, x_ques.shape, c_mask.shape, q_mask.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "from tensorflow.keras.regularizers import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class context2query_attention(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, c_maxlen, q_maxlen, dropout, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.c_maxlen = c_maxlen\n",
    "        self.q_maxlen = q_maxlen\n",
    "        self.dropout = dropout\n",
    "        super(context2query_attention, self).__init__(**kwargs)\n",
    "\n",
    "    '''\n",
    "    build(input_shape): 这是你定义权重的地方。这个方法必须设 self.built = True，可以通过调用 super([Layer], self).build() 完成\n",
    "    '''\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape: [(None, ?, 128), (None, ?, 128)]\n",
    "        init = VarianceScaling(scale=1.0, mode='fan_avg', distribution='uniform')\n",
    "        self.W0 = self.add_weight(name='W0',\n",
    "                                  shape=(input_shape[0][-1], 1),\n",
    "                                  initializer=init,\n",
    "                                  regularizer=l2(3e-7),\n",
    "                                  trainable=True)\n",
    "        self.W1 = self.add_weight(name='W1',\n",
    "                                  shape=(input_shape[1][-1], 1),\n",
    "                                  initializer=init,\n",
    "                                  regularizer=l2(3e-7),\n",
    "                                  trainable=True)\n",
    "        self.W2 = self.add_weight(name='W2',\n",
    "                                  shape=(1, 1, input_shape[0][-1]),\n",
    "                                  initializer=init,\n",
    "                                  regularizer=l2(3e-7),\n",
    "                                  trainable=True)\n",
    "        self.bias = self.add_weight(name='linear_bias',\n",
    "                                    shape=([1]),\n",
    "                                    initializer='zero',\n",
    "                                    regularizer=l2(3e-7),\n",
    "                                    trainable=True)\n",
    "        super(context2query_attention, self).build(input_shape)\n",
    "\n",
    "    def mask_logits(self, inputs, mask, mask_value=-1e30):\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "        return inputs + mask_value * (1 - mask)\n",
    "    \n",
    "    '''\n",
    "    call(x): 这里是编写层的功能逻辑的地方。你只需要关注传入 call 的第一个参数：输入张量，除非你希望你的层支持masking。\n",
    "    '''\n",
    "\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        x_cont, x_ques, c_mask, q_mask = x\n",
    "        # get similarity matrix S\n",
    "        subres0 = K.tile(K.dot(x_cont, self.W0), [1, 1, self.q_maxlen])\n",
    "        subres1 = K.tile(K.permute_dimensions(K.dot(x_ques, self.W1), pattern=(0, 2, 1)), [1, self.c_maxlen, 1])\n",
    "        subres2 = K.batch_dot(x_cont * self.W2, K.permute_dimensions(x_ques, pattern=(0, 2, 1)))\n",
    "        S = subres0 + subres1 + subres2\n",
    "        S += self.bias\n",
    "        q_mask = tf.expand_dims(q_mask, 1)\n",
    "        S_ = tf.nn.softmax(self.mask_logits(S, q_mask))\n",
    "        c_mask = tf.expand_dims(c_mask, 2)\n",
    "        S_T = K.permute_dimensions(tf.nn.softmax(self.mask_logits(S, c_mask), axis=1), (0, 2, 1))\n",
    "        c2q = tf.matmul(S_, x_ques)\n",
    "        q2c = tf.matmul(tf.matmul(S_, S_T), x_cont)\n",
    "        result = K.concatenate([x_cont, c2q, x_cont * c2q, x_cont * q2c], axis=-1)\n",
    "        #result Tensor(\"context2query_attention/concat_2:0\", shape=(None, None, 512), dtype=float32)\n",
    "        print('result',result.shape)\n",
    "        return result\n",
    "\n",
    "    '''\n",
    "    compute_output_shape(input_shape): 如果你的层更改了输入张量的形状，你应该在这里定义形状变化的逻辑，这让Keras能够自动推断各层的形状\n",
    "    '''\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1], self.output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result (None, None, 512)\n",
      "Context_to_Query_Attention_Layer x (None, None, 512)\n"
     ]
    }
   ],
   "source": [
    "# Context_to_Query_Attention_Layer\n",
    "##512, c_maxlen, q_maxlen, dropout初始化该层的类，输入为[x_cont, x_ques, c_mask, q_mask]\n",
    "\n",
    "\n",
    "x = context2query_attention(512, c_maxlen, q_maxlen, dropout)([x_cont, x_ques, c_mask, q_mask])\n",
    "\n",
    "print('Context_to_Query_Attention_Layer x',x.shape)\n",
    "x = Conv1D(filters, 1,\n",
    "           kernel_initializer=init,\n",
    "           kernel_regularizer=regularizer,\n",
    "           activation='linear')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (None, None, 128)\n"
     ]
    }
   ],
   "source": [
    "print('x',x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_Encoder_Layer\n",
    "# shared layers\n",
    "Encoder_DepthwiseConv2 = []\n",
    "Encoder_SelfAttention2 = []\n",
    "Encoder_FeedForward2 = []\n",
    "for i in range(3):#7\n",
    "    DepthwiseConv_share_2_temp = []\n",
    "    for i in range(2):\n",
    "        DepthwiseConv_share_2_temp.append(DepthwiseConv1D(5, filters))\n",
    "\n",
    "    Encoder_DepthwiseConv2.append(DepthwiseConv_share_2_temp)\n",
    "    Encoder_SelfAttention2.append([Conv1D(2 * filters, 1,\n",
    "                                          kernel_initializer=init,\n",
    "                                          kernel_regularizer=regularizer),\n",
    "                                   Conv1D(filters, 1,\n",
    "                                          kernel_initializer=init,\n",
    "                                          kernel_regularizer=regularizer),\n",
    "                                   MultiHeadAttention(filters, num_head, dropout=dropout, bias=False)])\n",
    "    Encoder_FeedForward2.append([Conv1D(filters, 1,\n",
    "                                        kernel_initializer=init,\n",
    "                                        kernel_regularizer=regularizer,\n",
    "                                        activation='relu'),\n",
    "                                 Conv1D(filters, 1,\n",
    "                                        kernel_initializer=init,\n",
    "                                        kernel_regularizer=regularizer,\n",
    "                                        activation='linear')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [x]\n",
    "for i in range(1):#3\n",
    "    x = outputs[-1]\n",
    "    for j in range(3):#7\n",
    "        x = PositionEmbedding()(x)\n",
    "        x = conv_block(Encoder_DepthwiseConv2[j], x, 2, dropout, l=j, L=7)\n",
    "        x = attention_block(Encoder_SelfAttention2[j], x, c_mask, dropout, l=j, L=7)\n",
    "        x = feed_forward_block(Encoder_FeedForward2[j], x, dropout, l=j, L=7)\n",
    "    outputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(outputs) 2\n",
      "shape 0 (None, None, 128)\n",
      "shape 1 (None, None, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nlen(outputs) 2\\nshape 0 (300, 400, 128)原来的输入\\nshape 1 (300, 400, 128)后面新增的一个\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('len(outputs)',len(outputs))\n",
    "for index,each in enumerate(outputs):\n",
    "    print('shape',index,each.shape)\n",
    "'''\n",
    "len(outputs) 2\n",
    "shape 0 (300, 400, 128)原来的输入\n",
    "shape 1 (300, 400, 128)后面新增的一个\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output_Layer\n",
    "###类似于bert encoder端的输出，维度是：（batch_size,time_step,dim）\n",
    "#通过conv1D（1,1，）之后变为 x_start (None, None, 1)\n",
    "#再经过squeeze之后变为x_start (None, None)#（batch_size,time_step），每个step对应一个开始的位置\n",
    "#然后就可以计算start_softmax了；mask_logits x_start (None, None)；x_start softmax (None, None)\n",
    "\n",
    "\n",
    "# x_start = Concatenate()([outputs[1], outputs[2]])\n",
    "\n",
    "##直接用outputs[1]判断该位置是否是答案即可，现在的模式是答案只有一个词，所有只有需要判断是否，而不需要判断开始和结束位置\n",
    "x_start = outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_start (None, None, 128)\n"
     ]
    }
   ],
   "source": [
    "print('x_start',x_start.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_logits(inputs, mask, mask_value=-1e30):\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    return inputs + mask_value * (1 - mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1D x_start (None, None, 1)\n",
      "squeeze x_start (None, None)\n",
      "mask_logits x_start (None, None)\n",
      "x_start softmax (None, None)\n"
     ]
    }
   ],
   "source": [
    "x_start = Conv1D(1, 1,\n",
    "                 kernel_initializer=init,\n",
    "                 kernel_regularizer=regularizer,\n",
    "                 activation='linear')(x_start)\n",
    "\n",
    "print('conv1D x_start',x_start.shape)\n",
    "\n",
    "#从tensor中删除所有大小是1的维度\n",
    "x_start = Lambda(lambda x: tf.squeeze(x, axis=-1))(x_start)\n",
    "\n",
    "print('squeeze x_start',x_start.shape)\n",
    "\n",
    "## mask_logits输出维度与输入维度一样\n",
    "x_start = Lambda(lambda x: mask_logits(x[0], x[1]))([x_start, c_mask])\n",
    "\n",
    "print('mask_logits x_start',x_start.shape)\n",
    "\n",
    "\n",
    "##输出的x_start是已经经过了softmax计算之后的值\n",
    "\n",
    "'''\n",
    "softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "Returns:\n",
    "A `Tensor`. Has the same type and shape as `logits`.\n",
    "axis: The dimension softmax would be performed on. The default is -1 which\n",
    "      indicates the last dimension.\n",
    "'''\n",
    "x_start = Lambda(lambda x: K.softmax(x), name='start')(x_start)  # [bs, len]\n",
    "\n",
    "print('x_start softmax',x_start.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(2, 4) dtype=float32>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# def mask_logits(inputs, mask, mask_value=-1e30):\n",
    "#     mask = tf.cast(mask, tf.float32)\n",
    "#     return inputs + mask_value * (1 - mask)\n",
    "\n",
    "ones=tf.ones((2,3))\n",
    "zeros=tf.zeros((2,1))\n",
    "zeros\n",
    "tf.concat([ones,zeros],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.regularizers import *\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class QAoutputBlock(Layer):\n",
    "    def __init__(self, ans_limit=30, **kwargs):\n",
    "        self.ans_limit = ans_limit\n",
    "        super(QAoutputBlock, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(QAoutputBlock, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "#         不需要做mask因为与答案长度无关，不涉及开始和结束位置，只是是否\n",
    "#         x_shape=x.shape\n",
    "#         ones=tf.ones((x_shape[0],self.ans_limit))\n",
    "#         zeros=tf.zeros((x_shape[0],x_shape[0]-self.ans_limit))\n",
    "#         mask_self=tf.concat([ones,zeros],axis=1)\n",
    "#         x=mask_logits(x, mask_self)\n",
    "#         print('mask x',x.shape,x)\n",
    "\n",
    "\n",
    "\n",
    "#         x1 = x\n",
    "#         outer = tf.matmul(tf.expand_dims(x1, axis=2), tf.expand_dims(x2, axis=1))\n",
    "#         #num_lower:下三角矩阵保留的副对角线数量，从主对角线开始计算，相当于下三角的带宽。取值为负数时，则全部保留。\n",
    "#         #num_upper:上三角矩阵保留的副对角线数量，从主对角线开始计算，相当于上三角的带宽。取值为负数时，则全部保留。\n",
    "#         #本程序中下三角不保留一行，上三角保留答案个长度\n",
    "#         #开始的位置一定在结束的位置前面，所以只取上三角部分；行对应开始位置，列对应结束位置\n",
    "#         ##答案的长度：从开始位置到结束位置；第一行0-ans_limit,第二行1-ans_limit+1一直到所有的情况\n",
    "#         outer = tf.linalg.band_part(outer, 0, self.ans_limit)#（batch_size,start_steop,end_step)\n",
    "        \n",
    "#         #列取索引，就是对应第几行，就是开始的索引位置；即对每个结束位置固定后，每个开始位置计算，取乘积最大的作为开始位置\n",
    "        \n",
    "#         ##output1和output2似乎是在验证评估时使用，训练时不使用\n",
    "#         output1 = tf.reshape(tf.cast(tf.argmax(tf.reduce_max(outer, axis=2), axis=1), tf.float32),(-1,1))\n",
    "        \n",
    "#         ##与上面对应：结束位置索引即对每个开始位置固定后，每个结束位置计算，取乘积最大的作为结束位置\n",
    "#         output2 = tf.reshape(tf.cast(tf.argmax(tf.reduce_max(outer, axis=1), axis=1), tf.float32),(-1,1))\n",
    "        \n",
    "        ##感觉要把超过答案长度的x地方变为0；用一个mask操作就可以了变成非常小的数\n",
    "    \n",
    "        \n",
    "        output1=tf.reshape(tf.cast(tf.argmax(x, axis=1), tf.float32),(-1,1))\n",
    "\n",
    "        return output1\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "def shape_list(x):\n",
    "  \"\"\"Return list of dims, statically where possible.\"\"\"\n",
    "  x = tf.convert_to_tensor(x)\n",
    "\n",
    "  # If unknown rank, return dynamic shape\n",
    "  if x.get_shape().dims is None:\n",
    "    return tf.shape(x)\n",
    "\n",
    "  static = x.get_shape().as_list()\n",
    "  shape = tf.shape(x)\n",
    "\n",
    "  ret = []\n",
    "  for i in range(len(static)):\n",
    "    dim = static[i]\n",
    "    if dim is None:\n",
    "      dim = shape[i]\n",
    "    ret.append(dim)\n",
    "  return ret\n",
    "\n",
    "class LabelPadding(Layer):\n",
    "    def __init__(self, max_len, **kwargs):\n",
    "        self.max_len = max_len\n",
    "        super(LabelPadding, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(LabelPadding, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None, training=None):\n",
    "        tensor_shape = shape_list(x) # [bs, len]\n",
    "        zero_paddings = tf.zeros((tensor_shape[0], self.max_len - tensor_shape[1]))\n",
    "        x = tf.concat([x, zero_paddings], axis=-1)\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 ,x2 = [x_start, x_end]\n",
    "# outer = tf.matmul(tf.expand_dims(x1, axis=2), tf.expand_dims(x2, axis=1))\n",
    "# outer = tf.linalg.band_part(outer, 0,ans_limit)#（batch_size,start_steop,end_step)\n",
    "# print('outer ',outer.shape)\n",
    "# # #列取索引，就是对应第几行，就是开始的索引位置；即对每个结束位置固定后，每个开始位置计算，取乘积最大的作为开始位置\n",
    "\n",
    "# # ##output1和output2似乎是在验证评估时使用，训练时不使用\n",
    "# # output1 = tf.reshape(tf.cast(tf.argmax(tf.reduce_max(outer, axis=2), axis=1), tf.float32),(-1,1))\n",
    "\n",
    "# # ##与上面对应：结束位置索引即对每个开始位置固定后，每个结束位置计算，取乘积最大的作为结束位置\n",
    "# # output2 = tf.reshape(tf.cast(tf.argmax(tf.reduce_max(outer, axis=1), axis=1), tf.float32),(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.reduce_max(outer, axis=2).shape)\n",
    "# print(tf.argmax(tf.reduce_max(outer, axis=2), axis=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.reduce_max(outer, axis=1).shape)\n",
    "# print(tf.argmax(tf.reduce_max(outer, axis=1), axis=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1106 04:54:09.852091 139837375031040 ag_logging.py:146] Entity <bound method QAoutputBlock.call of <__main__.QAoutputBlock object at 0x7f2d8df98400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method QAoutputBlock.call of <__main__.QAoutputBlock object at 0x7f2d8df98400>>, which Python reported as:\n",
      "    def call(self, x, mask=None):\n",
      "#         不需要做mask因为与答案长度无关，不涉及开始和结束位置，只是是否\n",
      "#         x_shape=x.shape\n",
      "#         ones=tf.ones((x_shape[0],self.ans_limit))\n",
      "#         zeros=tf.zeros((x_shape[0],x_shape[0]-self.ans_limit))\n",
      "#         mask_self=tf.concat([ones,zeros],axis=1)\n",
      "#         x=mask_logits(x, mask_self)\n",
      "#         print('mask x',x.shape,x)\n",
      "\n",
      "\n",
      "\n",
      "#         x1 = x\n",
      "#         outer = tf.matmul(tf.expand_dims(x1, axis=2), tf.expand_dims(x2, axis=1))\n",
      "#         #num_lower:下三角矩阵保留的副对角线数量，从主对角线开始计算，相当于下三角的带宽。取值为负数时，则全部保留。\n",
      "#         #num_upper:上三角矩阵保留的副对角线数量，从主对角线开始计算，相当于上三角的带宽。取值为负数时，则全部保留。\n",
      "#         #本程序中下三角不保留一行，上三角保留答案个长度\n",
      "#         #开始的位置一定在结束的位置前面，所以只取上三角部分；行对应开始位置，列对应结束位置\n",
      "#         ##答案的长度：从开始位置到结束位置；第一行0-ans_limit,第二行1-ans_limit+1一直到所有的情况\n",
      "#         outer = tf.linalg.band_part(outer, 0, self.ans_limit)#（batch_size,start_steop,end_step)\n",
      "        \n",
      "#         #列取索引，就是对应第几行，就是开始的索引位置；即对每个结束位置固定后，每个开始位置计算，取乘积最大的作为开始位置\n",
      "        \n",
      "#         ##output1和output2似乎是在验证评估时使用，训练时不使用\n",
      "#         output1 = tf.reshape(tf.cast(tf.argmax(tf.reduce_max(outer, axis=2), axis=1), tf.float32),(-1,1))\n",
      "        \n",
      "#         ##与上面对应：结束位置索引即对每个开始位置固定后，每个结束位置计算，取乘积最大的作为结束位置\n",
      "#         output2 = tf.reshape(tf.cast(tf.argmax(tf.reduce_max(outer, axis=1), axis=1), tf.float32),(-1,1))\n",
      "        \n",
      "        ##感觉要把超过答案长度的x地方变为0；用一个mask操作就可以了变成非常小的数\n",
      "    \n",
      "        \n",
      "        output1=tf.reshape(tf.cast(tf.argmax(x, axis=1), tf.float32),(-1,1))\n",
      "\n",
      "        return output1\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method QAoutputBlock.call of <__main__.QAoutputBlock object at 0x7f2d8df98400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method QAoutputBlock.call of <__main__.QAoutputBlock object at 0x7f2d8df98400>>, which Python reported as:\n",
      "    def call(self, x, mask=None):\n",
      "#         不需要做mask因为与答案长度无关，不涉及开始和结束位置，只是是否\n",
      "#         x_shape=x.shape\n",
      "#         ones=tf.ones((x_shape[0],self.ans_limit))\n",
      "#         zeros=tf.zeros((x_shape[0],x_shape[0]-self.ans_limit))\n",
      "#         mask_self=tf.concat([ones,zeros],axis=1)\n",
      "#         x=mask_logits(x, mask_self)\n",
      "#         print('mask x',x.shape,x)\n",
      "\n",
      "\n",
      "\n",
      "#         x1 = x\n",
      "#         outer = tf.matmul(tf.expand_dims(x1, axis=2), tf.expand_dims(x2, axis=1))\n",
      "#         #num_lower:下三角矩阵保留的副对角线数量，从主对角线开始计算，相当于下三角的带宽。取值为负数时，则全部保留。\n",
      "#         #num_upper:上三角矩阵保留的副对角线数量，从主对角线开始计算，相当于上三角的带宽。取值为负数时，则全部保留。\n",
      "#         #本程序中下三角不保留一行，上三角保留答案个长度\n",
      "#         #开始的位置一定在结束的位置前面，所以只取上三角部分；行对应开始位置，列对应结束位置\n",
      "#         ##答案的长度：从开始位置到结束位置；第一行0-ans_limit,第二行1-ans_limit+1一直到所有的情况\n",
      "#         outer = tf.linalg.band_part(outer, 0, self.ans_limit)#（batch_size,start_steop,end_step)\n",
      "        \n",
      "#         #列取索引，就是对应第几行，就是开始的索引位置；即对每个结束位置固定后，每个开始位置计算，取乘积最大的作为开始位置\n",
      "        \n",
      "#         ##output1和output2似乎是在验证评估时使用，训练时不使用\n",
      "#         output1 = tf.reshape(tf.cast(tf.argmax(tf.reduce_max(outer, axis=2), axis=1), tf.float32),(-1,1))\n",
      "        \n",
      "#         ##与上面对应：结束位置索引即对每个开始位置固定后，每个结束位置计算，取乘积最大的作为结束位置\n",
      "#         output2 = tf.reshape(tf.cast(tf.argmax(tf.reduce_max(outer, axis=1), axis=1), tf.float32),(-1,1))\n",
      "        \n",
      "        ##感觉要把超过答案长度的x地方变为0；用一个mask操作就可以了变成非常小的数\n",
      "    \n",
      "        \n",
      "        output1=tf.reshape(tf.cast(tf.argmax(x, axis=1), tf.float32),(-1,1))\n",
      "\n",
      "        return output1\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "x_start  x_start_fin   (None, None) (None, 1)\n"
     ]
    }
   ],
   "source": [
    "##找到最大概率值对应的索引位置\n",
    "x_start_fin = QAoutputBlock(ans_limit, name='qa_output')(x_start)\n",
    "\n",
    "# if use model.fit, the output shape must be padded to the max length\n",
    "x_start = LabelPadding(cont_limit, name='start_pos')(x_start)\n",
    "# x_end = LabelPadding(cont_limit, name='end_pos')(x_end)\n",
    "print('x_start  x_start_fin  ',x_start.shape,x_start_fin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_start_fin\n",
    "# x_end_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs__=[contw_input_, quesw_input_, contc_input_, quesc_input_]\n",
    "# inputs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "一个简单的分类模型\n",
    "input_x = tf.keras.Input(shape=(72,))\n",
    "hidden1 = layers.Dense(32, activation='relu')(input_x)\n",
    "hidden2 = layers.Dense(16, activation='relu')(hidden1)\n",
    "pred = layers.Dense(10, activation='softmax')(hidden2)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_x, outputs=pred)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=5)\n",
    "'''\n",
    "##原始qanet模型\n",
    "# model=Model(inputs=[contw_input_, quesw_input_, contc_input_, quesc_input_],\n",
    "#                  outputs=[x_start, x_end, x_start_fin, x_end_fin])\n",
    "model=Model(inputs=[contw_input_, quesw_input_, contc_input_, quesc_input_],\n",
    "                 outputs=[x_start, x_start_fin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None, 16)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None, 16)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_slice_2 (BatchSlice)      (None, None, None)   0           input_3[0][0]                    \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_slice_3 (BatchSlice)      (None, None, None)   0           input_4[0][0]                    \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (Embedding)      (None, None, None, 6 78912       batch_slice_2[0][0]              \n",
      "                                                                 batch_slice_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 16, 64)       0           char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16, 64)       0           char_embedding[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "char_conv (Conv1D)              (None, 12, 128)      41088       lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_slice (BatchSlice)        (None, None)         0           input_1[0][0]                    \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           char_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_slice_1 (BatchSlice)      (None, None)         0           input_2[0][0]                    \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           char_conv[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "word_embedding (Embedding)      (None, None, 300)    3000000     batch_slice[0][0]                \n",
      "                                                                 batch_slice_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, None, 128)    0           global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, None, 128)    0           global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 428)    0           word_embedding[0][0]             \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 428)    0           word_embedding[1][0]             \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "highway_input_projection (Conv1 (None, None, 128)    54912       concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "highway0_linear (Conv1D)        (None, None, 128)    16512       highway_input_projection[0][0]   \n",
      "                                                                 highway_input_projection[1][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 128)    0           highway0_linear[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "highway0_gate (Conv1D)          (None, None, 128)    16512       highway_input_projection[0][0]   \n",
      "                                                                 highway_input_projection[1][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 128)    0           highway0_linear[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, None, 128)    0           dropout[0][0]                    \n",
      "                                                                 highway0_gate[0][0]              \n",
      "                                                                 highway_input_projection[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, None, 128)    0           dropout_2[0][0]                  \n",
      "                                                                 highway0_gate[1][0]              \n",
      "                                                                 highway_input_projection[1][0]   \n",
      "__________________________________________________________________________________________________\n",
      "highway1_linear (Conv1D)        (None, None, 128)    16512       lambda_8[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 128)    0           highway1_linear[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "highway1_gate (Conv1D)          (None, None, 128)    16512       lambda_8[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 128)    0           highway1_linear[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, None, 128)    0           dropout_1[0][0]                  \n",
      "                                                                 highway1_gate[0][0]              \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, None, 128)    0           dropout_3[0][0]                  \n",
      "                                                                 highway1_gate[1][0]              \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding (Position_E (None, None, 128)    0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_1 (Position (None, None, 128)    0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, None, 128)    256         position__embedding[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, None, 128)    256         position__embedding_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 128)    0           layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, None, 128)    0           layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv1d (DepthwiseConv (None, None, 128)    17408       dropout_4[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout (LayerDropout)    (None, None, 128)    0           depthwise_conv1d[0][0]           \n",
      "                                                                 position__embedding[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_6 (LayerDropout)  (None, None, 128)    0           depthwise_conv1d[1][0]           \n",
      "                                                                 position__embedding_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, None, 128)    256         layer_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, None, 128)    256         layer_dropout_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv1d_1 (DepthwiseCo (None, None, 128)    17408       layer_normalization_1[0][0]      \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_1 (LayerDropout)  (None, None, 128)    0           depthwise_conv1d_1[0][0]         \n",
      "                                                                 layer_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_7 (LayerDropout)  (None, None, 128)    0           depthwise_conv1d_1[1][0]         \n",
      "                                                                 layer_dropout_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, None, 128)    256         layer_dropout_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, None, 128)    256         layer_dropout_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 128)    0           layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, None, 128)    0           layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv1d_2 (DepthwiseCo (None, None, 128)    17408       dropout_5[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_2 (LayerDropout)  (None, None, 128)    0           depthwise_conv1d_2[0][0]         \n",
      "                                                                 layer_dropout_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_8 (LayerDropout)  (None, None, 128)    0           depthwise_conv1d_2[1][0]         \n",
      "                                                                 layer_dropout_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, None, 128)    256         layer_dropout_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (None, None, 128)    256         layer_dropout_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv1d_3 (DepthwiseCo (None, None, 128)    17408       layer_normalization_3[0][0]      \n",
      "                                                                 layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_3 (LayerDropout)  (None, None, 128)    0           depthwise_conv1d_3[0][0]         \n",
      "                                                                 layer_dropout_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_9 (LayerDropout)  (None, None, 128)    0           depthwise_conv1d_3[1][0]         \n",
      "                                                                 layer_dropout_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, None, 128)    256         layer_dropout_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNo (None, None, 128)    256         layer_dropout_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, None, 128)    0           layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, None, 128)    0           layer_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 256)    33024       dropout_6[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 128)    16512       dropout_6[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_slice_4 (BatchSlice)      (None, None)         0           lambda[0][0]                     \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_slice_5 (BatchSlice)      (None, None)         0           lambda_1[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, None, 128)    0           conv1d[0][0]                     \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "                                                                 batch_slice_4[0][0]              \n",
      "                                                                 conv1d[1][0]                     \n",
      "                                                                 conv1d_1[1][0]                   \n",
      "                                                                 batch_slice_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_4 (LayerDropout)  (None, None, 128)    0           multi_head_attention[0][0]       \n",
      "                                                                 layer_dropout_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_10 (LayerDropout) (None, None, 128)    0           multi_head_attention[1][0]       \n",
      "                                                                 layer_dropout_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, None, 128)    256         layer_dropout_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNo (None, None, 128)    256         layer_dropout_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, None, 128)    0           layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, None, 128)    0           layer_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 128)    16512       dropout_7[0][0]                  \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 128)    16512       conv1d_2[0][0]                   \n",
      "                                                                 conv1d_2[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_5 (LayerDropout)  (None, None, 128)    0           conv1d_3[0][0]                   \n",
      "                                                                 layer_dropout_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_11 (LayerDropout) (None, None, 128)    0           conv1d_3[1][0]                   \n",
      "                                                                 layer_dropout_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "context2query_attention (contex (None, None, 512)    385         layer_dropout_5[0][0]            \n",
      "                                                                 layer_dropout_11[0][0]           \n",
      "                                                                 batch_slice_4[0][0]              \n",
      "                                                                 batch_slice_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 128)    65664       context2query_attention[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_2 (Position (None, None, 128)    0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, None, 128)    256         position__embedding_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, None, 128)    0           layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv1d_4 (DepthwiseCo (None, None, 128)    17152       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_12 (LayerDropout) (None, None, 128)    0           depthwise_conv1d_4[0][0]         \n",
      "                                                                 position__embedding_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNo (None, None, 128)    256         layer_dropout_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv1d_5 (DepthwiseCo (None, None, 128)    17152       layer_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_13 (LayerDropout) (None, None, 128)    0           depthwise_conv1d_5[0][0]         \n",
      "                                                                 layer_dropout_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, None, 128)    256         layer_dropout_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, None, 128)    0           layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 256)    33024       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 128)    16512       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, None, 128)    0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "                                                                 batch_slice_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_14 (LayerDropout) (None, None, 128)    0           multi_head_attention_1[0][0]     \n",
      "                                                                 layer_dropout_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_15 (LayerNo (None, None, 128)    256         layer_dropout_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, None, 128)    0           layer_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, None, 128)    16512       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, None, 128)    16512       conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_15 (LayerDropout) (None, None, 128)    0           conv1d_8[0][0]                   \n",
      "                                                                 layer_dropout_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_3 (Position (None, None, 128)    0           layer_dropout_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, None, 128)    256         position__embedding_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, None, 128)    0           layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv1d_6 (DepthwiseCo (None, None, 128)    17152       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_16 (LayerDropout) (None, None, 128)    0           depthwise_conv1d_6[0][0]         \n",
      "                                                                 position__embedding_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_17 (LayerNo (None, None, 128)    256         layer_dropout_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv1d_7 (DepthwiseCo (None, None, 128)    17152       layer_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_17 (LayerDropout) (None, None, 128)    0           depthwise_conv1d_7[0][0]         \n",
      "                                                                 layer_dropout_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_18 (LayerNo (None, None, 128)    256         layer_dropout_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, None, 128)    0           layer_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 256)    33024       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, None, 128)    16512       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, None, 128)    0           conv1d_9[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "                                                                 batch_slice_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_18 (LayerDropout) (None, None, 128)    0           multi_head_attention_2[0][0]     \n",
      "                                                                 layer_dropout_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_19 (LayerNo (None, None, 128)    256         layer_dropout_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, None, 128)    0           layer_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, None, 128)    16512       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, None, 128)    16512       conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_19 (LayerDropout) (None, None, 128)    0           conv1d_12[0][0]                  \n",
      "                                                                 layer_dropout_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "position__embedding_4 (Position (None, None, 128)    0           layer_dropout_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_20 (LayerNo (None, None, 128)    256         position__embedding_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, None, 128)    0           layer_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv1d_8 (DepthwiseCo (None, None, 128)    17152       dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_20 (LayerDropout) (None, None, 128)    0           depthwise_conv1d_8[0][0]         \n",
      "                                                                 position__embedding_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_21 (LayerNo (None, None, 128)    256         layer_dropout_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv1d_9 (DepthwiseCo (None, None, 128)    17152       layer_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_21 (LayerDropout) (None, None, 128)    0           depthwise_conv1d_9[0][0]         \n",
      "                                                                 layer_dropout_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_22 (LayerNo (None, None, 128)    256         layer_dropout_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, None, 128)    0           layer_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, None, 256)    33024       dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, None, 128)    16512       dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, None, 128)    0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "                                                                 batch_slice_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_22 (LayerDropout) (None, None, 128)    0           multi_head_attention_3[0][0]     \n",
      "                                                                 layer_dropout_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_23 (LayerNo (None, None, 128)    256         layer_dropout_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, None, 128)    0           layer_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, None, 128)    16512       dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, None, 128)    16512       conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_dropout_23 (LayerDropout) (None, None, 128)    0           conv1d_16[0][0]                  \n",
      "                                                                 layer_dropout_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, None, 1)      129         layer_dropout_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, None)         0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, None)         0           lambda_12[0][0]                  \n",
      "                                                                 batch_slice_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "start (Lambda)                  (None, None)         0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "start_pos (LabelPadding)        (None, None)         0           start[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "qa_output (QAoutputBlock)       (None, 1)            0           start[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 3,816,066\n",
      "Trainable params: 816,066\n",
      "Non-trainable params: 3,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.8, beta_2=0.999, epsilon=1e-7)\n",
    "\n",
    "##损失函数有4个应该是模型有4个输出，对应4个label,计算每个输出的损失函数，加权求和后最为最终的损失函数，权重即为loss_weights\n",
    "model.compile(optimizer=optimizer, loss=['categorical_crossentropy',  'mae'],\n",
    "              loss_weights=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 26s 85ms/sample - loss: 3143.0502 - start_pos_loss: 3142.3706 - qa_output_loss: 205.5296\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 26s 85ms/sample - loss: 3071.3109 - start_pos_loss: 3072.0767 - qa_output_loss: 213.0197\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 26s 86ms/sample - loss: 2869.2296 - start_pos_loss: 2859.1885 - qa_output_loss: 206.2862\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 26s 86ms/sample - loss: 1984.3227 - start_pos_loss: 1976.3104 - qa_output_loss: 196.9079\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 26s 86ms/sample - loss: 1373.8456 - start_pos_loss: 1373.5413 - qa_output_loss: 198.1908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2d68bdc550>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "##假设总共10000个单词，每个单词300维度 \n",
    "embedding_matrix = np.random.random((10000, 300))\n",
    "##总共1233个字符，每个字符64维度\n",
    "embedding_matrix_char = np.random.random((1233, 64))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    'word_dim': 300,\n",
    "    'char_dim': 64,\n",
    "    'cont_limit': 400,\n",
    "    'ques_limit': 50,\n",
    "    'char_limit': 16,\n",
    "    'ans_limit': 30,\n",
    "    'char_input_size': 1233,\n",
    "    'filters': 128,\n",
    "    'num_head': 8,\n",
    "    'dropout': 0.5,\n",
    "    'batch_size': 16,\n",
    "    'epoch': 25,\n",
    "    'ema_decay': 0.9999,\n",
    "    'learning_rate': 1e-3,\n",
    "    'path': 'QA001',\n",
    "    'use_cove': True\n",
    "}\n",
    "\n",
    "\n",
    "# load data\n",
    "char_dim = 200##好像没有使用\n",
    "cont_limit = 400\n",
    "ques_limit = 50\n",
    "char_limit = 16\n",
    "\n",
    "###0-10000之间的某个词模拟所有词的的index\n",
    "##embedding词典大小总共10000个单词；转成0-9999个索引对应，300个上下文，每个上下文长度最大为为400\n",
    "context_word = np.random.randint(0, 10000, (300, cont_limit))\n",
    "question_word = np.random.randint(0, 10000, (300, ques_limit))\n",
    "context_char = np.random.randint(0, 96, (300, cont_limit, char_limit))\n",
    "question_char = np.random.randint(0, 96, (300, ques_limit, char_limit))\n",
    "start_label = np.random.randint(0, 2, (300, cont_limit))\n",
    "end_label = np.random.randint(0, 2, (300, cont_limit))\n",
    "start_label_fin = np.argmax(start_label, axis=-1)\n",
    "end_label_fin = np.argmax(end_label, axis=-1)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# load data\n",
    "char_dim = 64\n",
    "cont_limit = 400\n",
    "ques_limit = 50\n",
    "char_limit = 16\n",
    "#生成维度为（300，cont_limit）,大小在0-10000之间的随机整数##上下文长度最大400个词，每个词的维度是300d（感觉不对，应该是有300个上下文）\n",
    "context_word = np.random.randint(0, 10000, (300, cont_limit))\n",
    "question_word = np.random.randint(0, 10000, (300, ques_limit))\n",
    "\n",
    "##最多400个词，每个词最多16个字符，字符维度也是300维度\n",
    "context_char = np.random.randint(0, 96, (300, cont_limit, char_limit))\n",
    "question_char = np.random.randint(0, 96, (300, ques_limit, char_limit))\n",
    "\n",
    "start_label = np.random.randint(0, 2, (300, cont_limit))\n",
    "end_label = np.random.randint(0, 2, (300, cont_limit))\n",
    "start_label_fin = np.argmax(start_label, axis=-1)\n",
    "end_label_fin = np.argmax(end_label, axis=-1)\n",
    "'''\n",
    "fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, \n",
    "validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, \n",
    "sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1)\n",
    "\n",
    "即\n",
    "x=[context_word, question_word, context_char, question_char],\n",
    "y=[start_label, end_label, start_label_fin, end_label_fin]\n",
    "\n",
    "Model(inputs=[contw_input_, quesw_input_, contc_input_, quesc_input_],\n",
    "                 outputs=[x_start, x_end, x_start_fin, x_end_fin])\n",
    "                 \n",
    "Model根据输入经过网络得到输出，输出和对应的label求出损失函数，损失函数加权后作为最终的损失函数，优化器使得最终的损失函数最小\n",
    "'''\n",
    "model.fit([context_word, question_word, context_char, question_char],\n",
    "          [start_label, start_label_fin], epochs=5,batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=model.predict([context_word, question_word, context_char, question_char], batch_size=8)\n",
    "##输出是由两个组成的列表：概率和概率最大值对应的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 400)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.argmax(preds[0][0]))\n",
    "len(preds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.0849361e-03, 1.7079145e-03, 1.1533032e-03, ..., 6.0750321e-05,\n",
       "        3.0189623e-05, 1.8625603e-04],\n",
       "       [4.9746213e-03, 2.3751134e-04, 2.2828185e-03, ..., 3.1152271e-05,\n",
       "        3.1695701e-05, 4.6815523e-05],\n",
       "       [1.8335383e-02, 3.9850865e-03, 8.6837780e-04, ..., 7.9354773e-05,\n",
       "        2.2068454e-05, 7.8192621e-05],\n",
       "       ...,\n",
       "       [4.8974296e-03, 6.3667720e-04, 8.3623582e-04, ..., 1.2348053e-05,\n",
       "        2.0187252e-04, 8.9222805e-05],\n",
       "       [3.1531921e-03, 3.8953437e-03, 5.2908561e-03, ..., 2.1761578e-05,\n",
       "        3.1898282e-05, 1.3399607e-05],\n",
       "       [5.8363359e-03, 1.4982633e-03, 5.3991904e-03, ..., 5.2872369e-05,\n",
       "        3.4635017e-05, 2.0366945e-04]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [67.],\n",
       "       [65.],\n",
       "       [67.],\n",
       "       [93.],\n",
       "       [67.],\n",
       "       [35.],\n",
       "       [92.],\n",
       "       [86.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [36.],\n",
       "       [93.],\n",
       "       [67.],\n",
       "       [68.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [35.],\n",
       "       [67.],\n",
       "       [35.],\n",
       "       [36.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [92.],\n",
       "       [35.],\n",
       "       [65.],\n",
       "       [36.],\n",
       "       [34.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [86.],\n",
       "       [34.],\n",
       "       [36.],\n",
       "       [66.],\n",
       "       [67.],\n",
       "       [65.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [67.],\n",
       "       [36.],\n",
       "       [65.],\n",
       "       [35.],\n",
       "       [65.],\n",
       "       [65.],\n",
       "       [86.],\n",
       "       [67.],\n",
       "       [85.],\n",
       "       [64.],\n",
       "       [66.],\n",
       "       [93.],\n",
       "       [65.],\n",
       "       [65.],\n",
       "       [65.],\n",
       "       [93.],\n",
       "       [66.],\n",
       "       [67.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [65.],\n",
       "       [65.],\n",
       "       [86.],\n",
       "       [66.],\n",
       "       [34.],\n",
       "       [35.],\n",
       "       [67.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [85.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [67.],\n",
       "       [35.],\n",
       "       [34.],\n",
       "       [67.],\n",
       "       [35.],\n",
       "       [92.],\n",
       "       [34.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [86.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [65.],\n",
       "       [66.],\n",
       "       [86.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [67.],\n",
       "       [65.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [66.],\n",
       "       [86.],\n",
       "       [67.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [65.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [93.],\n",
       "       [67.],\n",
       "       [86.],\n",
       "       [35.],\n",
       "       [67.],\n",
       "       [66.],\n",
       "       [67.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [86.],\n",
       "       [67.],\n",
       "       [67.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [92.],\n",
       "       [65.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [93.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [67.],\n",
       "       [67.],\n",
       "       [34.],\n",
       "       [67.],\n",
       "       [67.],\n",
       "       [86.],\n",
       "       [92.],\n",
       "       [86.],\n",
       "       [92.],\n",
       "       [85.],\n",
       "       [65.],\n",
       "       [86.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [93.],\n",
       "       [85.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [68.],\n",
       "       [92.],\n",
       "       [35.],\n",
       "       [65.],\n",
       "       [66.],\n",
       "       [93.],\n",
       "       [92.],\n",
       "       [67.],\n",
       "       [67.],\n",
       "       [87.],\n",
       "       [86.],\n",
       "       [66.],\n",
       "       [36.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [67.],\n",
       "       [65.],\n",
       "       [36.],\n",
       "       [65.],\n",
       "       [92.],\n",
       "       [35.],\n",
       "       [36.],\n",
       "       [85.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [67.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [16.],\n",
       "       [93.],\n",
       "       [66.],\n",
       "       [93.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [67.],\n",
       "       [67.],\n",
       "       [67.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [67.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [67.],\n",
       "       [66.],\n",
       "       [36.],\n",
       "       [67.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [67.],\n",
       "       [35.],\n",
       "       [93.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [93.],\n",
       "       [35.],\n",
       "       [34.],\n",
       "       [85.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [67.],\n",
       "       [65.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [67.],\n",
       "       [35.],\n",
       "       [92.],\n",
       "       [67.],\n",
       "       [67.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [92.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [65.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [73.],\n",
       "       [67.],\n",
       "       [35.],\n",
       "       [93.],\n",
       "       [86.],\n",
       "       [67.],\n",
       "       [34.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [93.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [66.],\n",
       "       [67.],\n",
       "       [65.],\n",
       "       [66.],\n",
       "       [36.],\n",
       "       [65.],\n",
       "       [85.],\n",
       "       [67.],\n",
       "       [86.],\n",
       "       [67.],\n",
       "       [67.],\n",
       "       [34.],\n",
       "       [86.],\n",
       "       [67.],\n",
       "       [65.],\n",
       "       [67.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [66.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [66.]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
